{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ELT Pipeline for the i94 immigration and temperature data sets.\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "To Provide a database of tablea optimized for analytical queries, example of those queries include:-\n",
    "    - Determine the top cities with most immegrations thier templeratures, the months with most immegrations.\n",
    "    - How many females and males travel and what is the average temperature of places they go to.\n",
    "    - The cities with the most emmigrations and the visa type for must people migrating to those cities.\n",
    "\n",
    "#### Goals\n",
    " Prepare an ETL Pipeline that loads i94 immegration and temperature data sets then model the data and produces tables optimized for query,\n",
    " load the tables into a  parquet files and save localy.\n",
    " \n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Project Scope and Data gathering\n",
    "\n",
    "### Scope\n",
    "For this project we will have 2 tables and 1 facts table. The first \"i9immegration\" table will be an aggregration be oraginal city and destination city on the i94 immigration data, the second table \"temperature\" will the an aggregation by the city on the temperature  data. The facts table will be produces by joining the two data sets on the origin city and destination city to produce \"immegrationandtemperature\" facts table.\n",
    "\n",
    "### Describe and Gather Data\n",
    "For the 2 data sets provided we will present with needed fields which will be fields we will select from the data set.\n",
    "\n",
    "From the i9migration data the following fields will be of intrenst\n",
    " - i94mon: Numeric month\n",
    " - i94cit: 3 numeric digit code from origin Country\n",
    " - i94port: 3 Character code for city in the US\n",
    " - i94visa: Visa code corresponding to three categories (1=Buisness, 2=Pleasure, 3=Student)\n",
    " - i94bir - Age of Respondent in Years\n",
    " - gender - Non-immigrant sex\n",
    " \n",
    "For the temperature data the following fields will be of intrest\n",
    " - AverageTemperature: average temperature\n",
    " - AverageTemperatureUncertainty: average temperature uncertainty\n",
    " - City: city name\n",
    " - Country: country name\n",
    " - Latitude: latitude\n",
    " - Longitude: longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Do imports \n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Set default options for pandas\n",
    "pd.set_option('max_colwidth', 10)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Initialize spark instance \n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Load i94migration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "migration_file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#pd_df =  pd.read_sas(migration_file, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_df = pd.read_csv('immigration_data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # define schema for immigration data\n",
    "i94immigration_schema = StructType([\n",
    "        StructField('', IntegerType()),\n",
    "        StructField('cicid', DoubleType()),\n",
    "        StructField('i94yr', DoubleType()),\n",
    "        StructField('i94mon', DoubleType()),\n",
    "        StructField('i94cit', DoubleType()),\n",
    "        StructField('i94res', DoubleType()),\n",
    "        StructField('i94port', StringType()),\n",
    "        StructField('arrdate', DoubleType()),\n",
    "        StructField('i94mode', DoubleType()),\n",
    "        StructField('i94addr', StringType()),\n",
    "        StructField('depdate', DoubleType()),\n",
    "        StructField('i94bir', DoubleType()),\n",
    "        StructField('i94visa', DoubleType()),\n",
    "        StructField('count', DoubleType()),\n",
    "        StructField('dtadfile', StringType()),\n",
    "        StructField('visapost', StringType()),\n",
    "        StructField('occup', StringType()),\n",
    "        StructField('entdepa', StringType()),\n",
    "        StructField('entdepd', StringType()),\n",
    "        StructField('entdepu', StringType()),\n",
    "        StructField('matflag', StringType()),\n",
    "        StructField('biryear', DoubleType()),\n",
    "        StructField('dtaddto', StringType()),\n",
    "        StructField('gender', StringType()),\n",
    "        StructField('insnum', StringType()),\n",
    "        StructField('airline', StringType()),\n",
    "        StructField('admnum', StringType()),\n",
    "        StructField('fltno', StringType()),\n",
    "        StructField('visatype', StringType())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert the pandas df to a spark dataframe\n",
    "imigrations_df = spark.createDataFrame(pd_df, schema=i94immigration_schema )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Load GlobalLandTemperaturesByCity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_schema = StructType([\n",
    "        StructField('dt', TimestampType()),\n",
    "        StructField('AverageTemperature', DoubleType()),\n",
    "        StructField('AverageTemperatureUncertainty', DoubleType()),\n",
    "        StructField('City', StringType()),\n",
    "        StructField('Latitude', DoubleType()),\n",
    "        StructField('Longitude', DoubleType())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_data = spark.read.schema(temperature_schema).format('csv').options(header='true', inferSchema='false').load(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "- Read valid codes for the i94cit and i94port from valid_i94cit.txt and valid_i94port.txt files\n",
    "* Revome all invalid country codes from the i94cit coloumn\n",
    "- Remoce all invalid code from the i94port column\n",
    "- Add coulumns for origin_country and destination_city\n",
    "- Remove all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Read Valil country and code\n",
    "file1 = open('valid_i94cit.txt', 'r') \n",
    "Lines = file1.readlines() \n",
    "# validcountry_list = []\n",
    "validcountry_dic = {}\n",
    "# Strips the newline character \n",
    "for line in Lines: \n",
    "    code, country = line.strip().split('=')\n",
    "    code = int(code.strip())\n",
    "    country = country.rsplit('(', 1)[0].replace(\"'\",\"\").strip()\n",
    "    \n",
    "#     validcountry_list.append({'code': code, 'country': country})\n",
    "    validcountry_dic.update({code : country})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf()\n",
    "def get_i94cit(code):\n",
    "      '''\n",
    "    Description: This function takes an i94cit (Country Code) and return the corresponding country name\n",
    "    \n",
    "    Parameters: \n",
    "        - Input: Country code\n",
    "        - Output: Corresponding City\n",
    "    '''\n",
    "    try:\n",
    "        return validcountry_dic[code]\n",
    "\n",
    "    except KeyError:\n",
    "        return None\n",
    "        \n",
    "#get_i94cit = udf(lambda code: validcountry_dic[code] )\n",
    "\n",
    "# Add iport94 code based on city name\n",
    "imigrations_df = imigrations_df.withColumn(\"origin_country\", get_i94cit(imigrations_df.i94cit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Read Valid cities and code\n",
    "file1 = open('valid_i94port.txt', 'r') \n",
    "Lines = file1.readlines() \n",
    "##validcity_list = []\n",
    "validcity_dic = {}\n",
    "\n",
    "# Strips the newline character \n",
    "for line in Lines: \n",
    "    code, city = line.strip().split('=')\n",
    "    code = code.replace(\"'\",\"\").strip()\n",
    "    city = city.split(',')[0].replace(\"'\",\"\").strip()\n",
    "\n",
    "    #validcity_dic.append({'code': code, 'city': city})\n",
    "    validcity_dic.update({code : country})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_i94port= udf(lambda code: validcountry_dic[key] )\n",
    "\n",
    "@udf()\n",
    "def get_i94cit(code):\n",
    "    '''\n",
    "    Description: This function takes an i94port (City Code) and return the corresponding city name\n",
    "    \n",
    "    Parameters: \n",
    "        - Input: city code\n",
    "        - Output: Corresponding City\n",
    "    '''\n",
    "    print(code)\n",
    "    try:\n",
    "        return validcountry_dic[code]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "# Add iport94 code based on city name\n",
    "imigrations_df = imigrations_df.withColumn(\"destination_city\", get_i94cit(migrations_df.i94port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df = temperature_data.selectExpr(\"AverageTemperature as average_temperature\", \"City as city\", \"Country as country\", \"Latitude as latitude\", \"Longitude as longitude\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df = temperature_df.filter(temperature_data.average_temperature != 'NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Data Modeling \n",
    "\n",
    "### 3.1 Conceptual Data Model\n",
    "Here we create are dimenstion and Facts tables as Defined in step 2\n",
    "\n",
    "From the i9migration data set we create a  *i9immegration* dimmension table\n",
    " - i94mon: Numeric month\n",
    " - i94cit: 3 numeric digit code from origin Country\n",
    " - i94port: 3 Character code for city in the US\n",
    " - i94visa: Visa code corresponding to three categories (1=Buisness, 2=Pleasure, 3=Student)\n",
    " - i94bir - Age of Respondent in Years\n",
    " - gender - Non-immigrant sex\n",
    "\n",
    " \n",
    "Fro, the temperature data the following fields will be extracted to make the *citytemperature* dimension table \n",
    " - AverageTemperature: average temperature\n",
    " - City: city name\n",
    " - Country: country name\n",
    " - Latitude: latitude\n",
    " - Longitude: longitude\n",
    " \n",
    "The Facts table will obtained from the i9immigration data set on join with the tables above to produce the table below\n",
    " - i94mon: Numeric month\n",
    " - i94cit: 3 numeric digit code from origin Country\n",
    " - i94port: 3 Character code for city in the US\n",
    " - i94visa: Visa code corresponding to three categories (1=Buisness, 2=Pleasure, 3=Student)\n",
    " - i94bir - Age of Respondent in Years\n",
    " - gender - Non-immigrant sex\n",
    " - country_of_origin: Contry represende by code\n",
    " - dest_city: Destination dity in the us \n",
    " - dest_temperature: Temperature of destination city\n",
    " \n",
    "### 3.2 Mapping Out Pipeline Steps\n",
    " Pipeline steps are listed below \n",
    " - Import data from sources\n",
    " - Clean the data \n",
    " - Select the required fields from both i94migration and temperature dataset to create dimension table.\n",
    " - Create a template view from data sets and dimension tables.\n",
    " - Create Facts table by joining the i9immigraion data and validcountry on i94cit join validcity on i94port join citytemperatur on city and country\n",
    " - Create a parquet file and persist all the tables created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imigrations_df = imigrations_df.select([\"cicid\",\"i94mon\", \"i94cit\", \"i94port\",\"i94visa\", \"i94bir\",\"gender\", \"origin_country\", \"destination_city\" ]).dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write immigration data to parquet file\n",
    "df_spark.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/parquets/i94immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_data = temperature_data.selectExpr(\"AverageTemperature as average_temperature\", \"City as city\", \"Country as country\", \"Latitude as latitude\", \"Longitude as longitude\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write temperature data to parquet file\n",
    "df_spark.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/parquets/i94immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Building the pipelines to create the data models as defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create template view for immigration data\n",
    "imigrations_df .createOrReplaceTempView('i9immegration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create template view for temperature data \n",
    "temperature_data.createOrReplaceTempView('temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create facts table from the dimensions table\n",
    "immigration_and_temperature = spark.sql('''\n",
    "            SELECT DISTINCT\n",
    "            im.i94mon,\n",
    "            im.i94cit,\n",
    "            im.i94port,\n",
    "            im.i94visa,\n",
    "            im.origin_country,\n",
    "            im.destination_city AS dest_city,\n",
    "            im.i94visa,\n",
    "            im.gender,\n",
    "            t.average_temperature AS dest_temperature\n",
    "            FROM i9immegration as im\n",
    "            JOIN temperature AS t ON im.destination_city=t.city\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_and_temperature.createOrReplaceTempView('immigration_temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "The data quality check will be ran to endure that all tables have entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_quality_check(table):\n",
    "    query = \"SELECT * FROM {} LIMIT 5\".format(table)\n",
    "    res = spark.sql(query)\n",
    "    if(len(res) < 1):\n",
    "         raise ValueError(f\"Data quality check failed. {table} returned no results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Run check for tables\n",
    "data_quality_check('i9immegration')\n",
    "data_quality_check('temperature')\n",
    "data_quality_check('immigration_temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model, each field listed with a brief description of what the data is and where it comes from. \n",
    "\n",
    "##### i94immigration(Dimension Table)\n",
    "Data here comes the i94immigration data set, the field used from this dataset include:-\n",
    " - i94mon: Numeric month\n",
    " - i94cit: 3 numeric digit code from origin Country\n",
    " - i94port: 3 Character code for city in the US\n",
    " - i94visa: Visa code corresponding to three categories (1=Buisness, 2=Pleasure, 3=Student)\n",
    " - i94bir: Age of Respondent in Years\n",
    " - gender: Non-immigrant sex\n",
    " - origin_country: Origin city gotten using the i94cit field property\n",
    " - destination_city: Destination city gotten using the i94port field property\n",
    "\n",
    "##### temperaturen(Dimension Table)\n",
    "Data here comes the GlobalLandTemperaturesByCity data set, the field used from this dataset include:-\n",
    " - average_temperature: average temperature\n",
    " - city: city name\n",
    " - country: country name\n",
    " - latitude: latitude\n",
    " - longitude: longitude\n",
    " \n",
    "##### temperaturen(Dimension Table)\n",
    "Data here comes the  i94immigration and GlobalLandTemperaturesByCity data sets joined by the city fiels, the field uses include:-\n",
    " - i94mon: Numeric month\n",
    " - i94cit: 3 numeric digit code from origin Country\n",
    " - i94port: 3 Character code for city in the US\n",
    " - i94visa: Visa code corresponding to three categories (1=Buisness, 2=Pleasure, 3=Student)\n",
    " - i94bir - Age of Respondent in Years\n",
    " - gender - Non-immigrant sex\n",
    " - country_of_origin: Contry represende by code\n",
    " - dest_city: Destination dity in the us \n",
    " - dest_temperature: Temperature of destination city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "##### Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "The choice of spark for etl in this process of this project is because its fast can perform advanced analytics and it's dynamic in nature to the number of file formats it can read.\n",
    "\n",
    "##### Propose how often the data should be updated and why.\n",
    "Given the analytical goals of this project related to producing analysis for movement per month it should be updated monthly.\n",
    "\n",
    "##### Below description's how the project will be approached based on the different scenarios:\n",
    "\n",
    "1. The data was increased by 100x.\n",
    "\n",
    "Given that data increases to 100X we will prefarable move spak to run on the cloud on a service optimized for that pupose like  AWS MRC which is optimized to for large data set by first dividing up the large dataset and distributing the data accross a cluster or clusters.\n",
    "\n",
    "2. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "For this reason we will use a tool like Airflow to that automated ETL pipelines, that way we shedule the pipline overnight or the evening of the preveous day.\n",
    "\n",
    "3. The database needed to be accessed by 100+ people.\n",
    "\n",
    "For this reason we could host the parquet files on an s3 bucket and give the read access externally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
